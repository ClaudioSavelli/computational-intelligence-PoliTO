{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from lab10 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dictionary, hit_state = train_loop(0.001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "training_steps = 100_000\n",
    "\n",
    "path = os.path.join(\"value_dictionaries\", f\"value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "\n",
    "# if file exists, load it\n",
    "try:\n",
    "    with open(path, 'rb') as f:\n",
    "        value_dictionary = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    value_dictionary, hit_state = train_loop(epsilon, training_steps)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(value_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = play_game(agent_move, \n",
    "            random_move, \n",
    "            value_dictionary=value_dictionary,\n",
    "            agent_player=1)\n",
    "\n",
    "if res == \"Player 1\":\n",
    "    print('Player 1 wins')\n",
    "elif res == \"Player 2\":\n",
    "    print('Player 2 wins')\n",
    "else:\n",
    "    print('Draw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = random_move\n",
    "agent_player = -1\n",
    "\n",
    "print('Random player(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2,\n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = agent_move\n",
    "player2 = random_move\n",
    "agent_player = 1\n",
    "\n",
    "print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2,\n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2, \n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2, \n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000, \n",
    "                trick=True)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalisation of the problem also on O "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "training_steps = 100_001\n",
    "\n",
    "path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "\n",
    "# if file exists, load it\n",
    "try:\n",
    "    with open(path, 'rb') as f:\n",
    "        complete_value_dictionary = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    complete_value_dictionary, complete_hit_state = complete_train_loop(epsilon, training_steps)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(complete_value_dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = complete_agent_move\n",
    "player2 = random_move\n",
    "agent_player = 1\n",
    "\n",
    "print('Random player(p1) vs agent(p2)') if agent_player == 2 else print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = complete_evaluate(player1, \n",
    "                        player2, \n",
    "                        complete_value_dictionary=complete_value_dictionary, \n",
    "                        agent_player=agent_player,\n",
    "                        games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = complete_agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)') if agent_player == 2 else print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = complete_evaluate(player1, \n",
    "                        player2, \n",
    "                        complete_value_dictionary=complete_value_dictionary, \n",
    "                        agent_player=agent_player,\n",
    "                        games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps_list = [125, 250, 500, 1_000, 2_000, 3_000, 4_000, 5_000, 7_500, 10_000, 25_000, 50_000, 100_000, 250_000, 500_000, 1_000_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_steps in training_steps_list: \n",
    "    path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            complete_value_dictionary = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        complete_value_dictionary, complete_hit_state = complete_train_loop(epsilon, training_steps)\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(complete_value_dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the different methods and see percentage of wins for each \n",
    "\n",
    "results = {}\n",
    "\n",
    "for training_steps in training_steps_list: \n",
    "    path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "    with open(path, 'rb') as f:\n",
    "        complete_value_dictionary = pickle.load(f)\n",
    "        \n",
    "    player1 = complete_agent_move\n",
    "    player2 = random_move\n",
    "    agent_player = 1\n",
    "    result = complete_evaluate(player1, \n",
    "                            player2, \n",
    "                            complete_value_dictionary=complete_value_dictionary, \n",
    "                            agent_player=agent_player,\n",
    "                            games=10_000)\n",
    "    k, v = np.unique(result, return_counts=True)\n",
    "    res = {key: value for key, value in zip(k, v)}\n",
    "    results[training_steps] = res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_results = defaultdict(dict)\n",
    "for k in results.keys():\n",
    "    plt_results[k][\"Wins\"] = results[k][\"Player 1\"] / 10_000\n",
    "    plt_results[k][\"Draws\"] = results[k][\"Draw\"] / 10_000\n",
    "    plt_results[k][\"Losses\"] = results[k][\"Player 2\"] / 10_000 if \"Player 2\" in results[k] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of the results\n",
    "\n",
    "for k in plt_results.keys():\n",
    "    print(f\"Training steps: {k}\")\n",
    "    print(f\"Wins: {plt_results[k]['Wins']}, Draws: {plt_results[k]['Draws']}, Losses: {plt_results[k]['Losses']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of results, each value has a dictionary with win, losses and draws\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "for i, training_steps in enumerate(training_steps_list):\n",
    "    col = i // 4\n",
    "    row = i % 4\n",
    "    ax[col, row].bar(plt_results[training_steps].keys(), plt_results[training_steps].values())\n",
    "    ax[col, row].set_title(f\"training steps: {training_steps}\")\n",
    "    ax[col, row].set_xlabel(\"Result\")\n",
    "    ax[col, row].set_ylabel(\"Count\")\n",
    "    ax[col, row].set_ylim(0, 1)\n",
    "    ax[col, row].set_xticks([0, 1, 2])\n",
    "    ax[col, row].set_xticklabels([\"Win\", \"Draw\", \"Loss\"])\n",
    "    ax[col, row].grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of numbers from 0 to 15 inclusive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of wins, draws and losses for each training step \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.plot(np.arange(len(plt_results.keys())), [plt_results[k][\"Wins\"] for k in plt_results.keys()], label=\"Wins\")\n",
    "ax.plot(np.arange(len(plt_results.keys())), [plt_results[k][\"Draws\"] for k in plt_results.keys()], label=\"Draws\")\n",
    "ax.plot(np.arange(len(plt_results.keys())), [plt_results[k][\"Losses\"] for k in plt_results.keys()], label=\"Losses\")\n",
    "ax.set_xlabel(\"Training steps\")\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_title(\"Percentage of wins, draws and losses for each training step\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random vs. Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the different methods and see percentage of wins for each \n",
    "\n",
    "results = {}\n",
    "\n",
    "for training_steps in training_steps_list: \n",
    "    path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "    with open(path, 'rb') as f:\n",
    "        complete_value_dictionary = pickle.load(f)\n",
    "        \n",
    "    player1 = random_move\n",
    "    player2 = complete_agent_move\n",
    "    agent_player = 2\n",
    "    result = complete_evaluate(player1, \n",
    "                            player2, \n",
    "                            complete_value_dictionary=complete_value_dictionary, \n",
    "                            agent_player=agent_player,\n",
    "                            games=10_000)\n",
    "    k, v = np.unique(result, return_counts=True)\n",
    "    res = {key: value for key, value in zip(k, v)}\n",
    "    results[training_steps] = res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_results = defaultdict(dict)\n",
    "for k in results.keys():\n",
    "    plt_results[k][\"Wins\"] = results[k][\"Player 2\"] / 10_000\n",
    "    plt_results[k][\"Draws\"] = results[k][\"Draw\"] / 10_000\n",
    "    plt_results[k][\"Losses\"] = results[k][\"Player 1\"] / 10_000 if \"Player 1\" in results[k] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of the results\n",
    "\n",
    "for k in plt_results.keys():\n",
    "    print(f\"Training steps: {k}\")\n",
    "    print(f\"Wins: {plt_results[k]['Wins']}, Draws: {plt_results[k]['Draws']}, Losses: {plt_results[k]['Losses']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of results, each value has a dictionary with win, losses and draws\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "for i, training_steps in enumerate(training_steps_list):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax[row, col].bar(plt_results[training_steps].keys(), plt_results[training_steps].values())\n",
    "    ax[row, col].set_title(f\"training steps: {training_steps}\")\n",
    "    ax[row, col].set_xlabel(\"Result\")\n",
    "    ax[row, col].set_ylabel(\"Count\")\n",
    "    ax[row, col].set_ylim(0, 1)\n",
    "    ax[row, col].set_xticks([0, 1, 2])\n",
    "    ax[row, col].set_xticklabels([\"Win\", \"Draw\", \"Loss\"])\n",
    "    ax[row, col].grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
