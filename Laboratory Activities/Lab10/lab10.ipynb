{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from lab10 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "training_steps = 500_000\n",
    "\n",
    "path = os.path.join(\"value_dictionaries\", f\"value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "\n",
    "# if file exists, load it\n",
    "try:\n",
    "    with open(path, 'rb') as f:\n",
    "        value_dictionary = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    value_dictionary, hit_state = train_loop(epsilon, training_steps)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(value_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(value_dictionary.items(), key=lambda e: e[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = play_game(agent_move, \n",
    "            random_move, \n",
    "            value_dictionary=value_dictionary,\n",
    "            agent_player=1)\n",
    "\n",
    "if res == \"Player 1\":\n",
    "    print('Player 1 wins')\n",
    "elif res == \"Player 2\":\n",
    "    print('Player 2 wins')\n",
    "else:\n",
    "    print('Draw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = random_move\n",
    "agent_player = -1\n",
    "\n",
    "print('Random player(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2,\n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = agent_move\n",
    "player2 = random_move\n",
    "agent_player = 1\n",
    "\n",
    "print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2,\n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2, \n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)')\n",
    "print()\n",
    "\n",
    "results = evaluate(player1, \n",
    "                player2, \n",
    "                value_dictionary=value_dictionary, \n",
    "                agent_player=agent_player,\n",
    "                games=10_000, \n",
    "                trick=True)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalisation of the problem also on O "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "training_steps = 500_000\n",
    "\n",
    "path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "\n",
    "# if file exists, load it\n",
    "try:\n",
    "    with open(path, 'rb') as f:\n",
    "        complete_value_dictionary = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    complete_value_dictionary, complete_hit_state = complete_train_loop(epsilon, training_steps)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(complete_value_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(complete_value_dictionary[\"x\"].items(), key=lambda e: e[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = complete_agent_move\n",
    "player2 = random_move\n",
    "agent_player = 1\n",
    "\n",
    "print('Random player(p1) vs agent(p2)') if agent_player == 2 else print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = complete_evaluate(player1, \n",
    "                        player2, \n",
    "                        complete_value_dictionary=complete_value_dictionary, \n",
    "                        agent_player=agent_player,\n",
    "                        games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = random_move\n",
    "player2 = complete_agent_move\n",
    "agent_player = 2\n",
    "\n",
    "print('Random player(p1) vs agent(p2)') if agent_player == 2 else print('Agent(p1) vs random player(p2)')\n",
    "print()\n",
    "\n",
    "results = complete_evaluate(player1, \n",
    "                        player2, \n",
    "                        complete_value_dictionary=complete_value_dictionary, \n",
    "                        agent_player=agent_player,\n",
    "                        games=10_000)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list = 0.001\n",
    "training_steps_list = [250, 1_000, 2_000, 3_000, 4_000, 5_000, 7_500, 10_000, 25_000, 500_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_steps in training_steps_list: \n",
    "    path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            complete_value_dictionary = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        complete_value_dictionary, complete_hit_state = complete_train_loop(epsilon, training_steps)\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(complete_value_dictionary, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the different methods and see percentage of wins for each \n",
    "\n",
    "results = {}\n",
    "\n",
    "for training_steps in training_steps_list: \n",
    "    path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "    with open(path, 'rb') as f:\n",
    "        complete_value_dictionary = pickle.load(f)\n",
    "        \n",
    "    player1 = complete_agent_move\n",
    "    player2 = random_move\n",
    "    agent_player = 1\n",
    "    result = complete_evaluate(player1, \n",
    "                            player2, \n",
    "                            complete_value_dictionary=complete_value_dictionary, \n",
    "                            agent_player=agent_player,\n",
    "                            games=10_000)\n",
    "    k, v = np.unique(result, return_counts=True)\n",
    "    res = {key: value for key, value in zip(k, v)}\n",
    "    results[(epsilon, training_steps)] = res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_results = defaultdict(dict)\n",
    "for k in results.keys():\n",
    "    plt_results[k][\"Wins\"] = results[k][\"Player 1\"] / 10_000\n",
    "    plt_results[k][\"Draws\"] = results[k][\"Draw\"] / 10_000\n",
    "    plt_results[k][\"Losses\"] = results[k][\"Player 2\"] / 10_000 if \"Player 2\" in results[k] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of the results\n",
    "\n",
    "for k in plt_results.keys():\n",
    "    print(f\"Epsilon: {k[0]}, Training steps: {k[1]}\")\n",
    "    print(f\"Wins: {plt_results[k]['Wins']}, Draws: {plt_results[k]['Draws']}, Losses: {plt_results[k]['Losses']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of results, each value has a dictionary with win, losses and draws\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(4, 6, figsize=(20, 20))\n",
    "\n",
    "for i, epsilon in enumerate(epsilon_list):\n",
    "    for j, training_steps in enumerate(training_steps_list):\n",
    "        ax[i, j].bar(plt_results[(epsilon, training_steps)].keys(), plt_results[(epsilon, training_steps)].values())\n",
    "        ax[i, j].set_title(f\"epsilon: {epsilon}, training steps: {training_steps}\")\n",
    "        ax[i, j].set_xlabel(\"Result\")\n",
    "        ax[i, j].set_ylabel(\"Count\")\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "        ax[i, j].set_xticks([0, 1, 2])\n",
    "        ax[i, j].set_xticklabels([\"Win\", \"Draw\", \"Loss\"])\n",
    "        ax[i, j].grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random vs. Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the different methods and see percentage of wins for each \n",
    "\n",
    "results = {}\n",
    "\n",
    "for epsilon in epsilon_list:\n",
    "    for training_steps in training_steps_list: \n",
    "        path = os.path.join(\"value_dictionaries\", f\"complete_value_dictionary_{epsilon}_{training_steps}.pkl\")\n",
    "        with open(path, 'rb') as f:\n",
    "            complete_value_dictionary = pickle.load(f)\n",
    "            \n",
    "        player1 = random_move\n",
    "        player2 = complete_agent_move\n",
    "        agent_player = 2\n",
    "        result = complete_evaluate(player1, \n",
    "                                player2, \n",
    "                                complete_value_dictionary=complete_value_dictionary, \n",
    "                                agent_player=agent_player,\n",
    "                                games=10_000)\n",
    "        k, v = np.unique(result, return_counts=True)\n",
    "        res = {key: value for key, value in zip(k, v)}\n",
    "        results[(epsilon, training_steps)] = res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_results = defaultdict(dict)\n",
    "for k in results.keys():\n",
    "    plt_results[k][\"Wins\"] = results[k][\"Player 1\"] / 10_000\n",
    "    plt_results[k][\"Draws\"] = results[k][\"Draw\"] / 10_000\n",
    "    plt_results[k][\"Losses\"] = results[k][\"Player 2\"] / 10_000 if \"Player 2\" in results[k] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of the results\n",
    "\n",
    "for k in plt_results.keys():\n",
    "    print(f\"Epsilon: {k[0]}, Training steps: {k[1]}\")\n",
    "    print(f\"Wins: {plt_results[k]['Wins']}, Draws: {plt_results[k]['Draws']}, Losses: {plt_results[k]['Losses']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of results, each value has a dictionary with win, losses and draws\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "for i, epsilon in enumerate(epsilon_list):\n",
    "    for j, training_steps in enumerate(training_steps_list):\n",
    "        ax[i, j].bar(plt_results[(epsilon, training_steps)].keys(), plt_results[(epsilon, training_steps)].values())\n",
    "        ax[i, j].set_title(f\"epsilon: {epsilon}, training steps: {training_steps}\")\n",
    "        ax[i, j].set_xlabel(\"Result\")\n",
    "        ax[i, j].set_ylabel(\"Count\")\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "        ax[i, j].set_xticks([0, 1, 2])\n",
    "        ax[i, j].set_xticklabels([\"Win\", \"Draw\", \"Loss\"])\n",
    "        ax[i, j].grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
